================================================
1. Quality Trimming and Filtering Your Sequences
================================================

.. shell start

Be aware of your space requirements and obtain an
appropriately sized machine ("instance") and storage ("volume").


On the new machine, run the following commands to update the base
software and reboot the machine::

   apt-get update
   apt-get -y install screen git curl gcc make g++ python-dev unzip default-jre \
              pkg-config libncurses5-dev r-base-core r-cran-gplots python-matplotlib\
              sysstat && shutdown -r now


Install software
----------------

.. clean up previous installs if we're re-running this...

.. ::

   set -x
   set -e
   echo Removing previous installs, if any.
   rm -fr /root/Trimmomatic-*
   rm -f /root/libgtextutils-*.bz2
   rm -f /root/fastx_toolkit-*.bz2
   rm -fr /root/bowtie2*
   rm -fr /root/samtools*

.. ::

   echo Clearing times.out
   mv -f /root/times.out /root/times.out.bak
   echo 1-quality INSTALL `date` >> /root/times.out

Install Bowtie2
::

   cd /root
   curl -L -O 'http://downloads.sourceforge.net/project/bowtie-bio/bowtie2/2.1.0/bowtie2-2.1.0-source.zip?r=http%3A%2F%2Fsourceforge.net%2Fprojects%2Fbowtie-bio%2Ffiles%2Fbowtie2%2F2.1.0%2F&ts=1365392377&use_mirror=superb-dca3'
   mv bowtie2-2.1.0-source.zip* bowtie2-2.1.0-source.zip
   unzip bowtie2-2.1.0-source
   cd bowtie2-2.1.0
   make
   cp bowtie2* /usr/local/bin

Install Samtools 
::

   cd /root
   curl -O -L http://sourceforge.net/projects/samtools/files/samtools/0.1.18/samtools-0.1.18.tar.bz2
   tar xvfj samtools-0.1.18.tar.bz2
   cd samtools-0.1.18
   make

Install `FastQC <http://www.bioinformatics.babraham.ac.uk/projects/fastqc/>`__::

   cd /usr/local/share
   curl -O http://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.10.1.zip
   unzip fastqc_v0.10.1.zip
   chmod +x FastQC/fastqc

Install `Trimmomatic <http://www.usadellab.org/cms/?page=trimmomatic>`__ :
::

   cd /root
   curl -O http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/Trimmomatic-0.30.zip
   unzip Trimmomatic-0.30.zip
   cd Trimmomatic-0.30/
   cp trimmomatic-0.30.jar /usr/local/bin
   cp -r adapters /usr/local/share/adapters

Install `libgtextutils and fastx <http://hannonlab.cshl.edu/fastx_toolkit/>`__ :
::

   cd /root
   curl -O http://hannonlab.cshl.edu/fastx_toolkit/libgtextutils-0.6.1.tar.bz2
   tar xjf libgtextutils-0.6.1.tar.bz2 
   cd libgtextutils-0.6.1/
   ./configure && make && make install
   
   cd /root
   curl -O http://hannonlab.cshl.edu/fastx_toolkit/fastx_toolkit-0.0.13.2.tar.bz2
   tar xjf fastx_toolkit-0.0.13.2.tar.bz2
   cd fastx_toolkit-0.0.13.2/
   ./configure && make && make install

In each of these cases, we're downloading the software -- you can use
google to figure out what each package is and does if we don't discuss
it below.  We're then unpacking it, sometimes compiling it (which we
can discuss later), and then installing it for general use.

* ASK: what is ibgtextutils for?

Find your data
--------------

If you downloaded the fastq files using ftp as in previous step, they should be in 'data' directory. The files usually have the '.fastq.gz' suffix.

If you see all the files you think you should, good!  Otherwise, debug.

Link your data into a working directory
---------------------------------------

Rather than *copying* the files into the working directory, let's just
*link* them in -- this creates a reference so that UNIX knows where to
find them but doesn't need to actually move them around. :
::

   cd /mnt
   mkdir -p work
   cd work
   
   ln -fs /data/*.fastq.gz .

(The 'ln' command does the linking.)

Now, do an 'ls' to list the files.  If you see only one entry, ``*.fastq.gz``,
then the ln command above didn't work properly.  One possibility is that
your files aren't in /data; another is that they're not named *.fastq.gz.

.. note::

   This protocol takes many hours to run, so you might not want
   to run it on all the data the first time.  If you're using the
   example data, you can work with a subset of it by running this command
   instead of the `ln -fs` command above::

      for file in /data/*.fastq.gz
      do
          gunzip -c $file | head -400000 | gzip > $(basename $file)
      done

   This will pull out the first 100,000 reads of each file (4 lines per record)
   and put them in the current directory, which should be /mnt/work.

OPTIONAL: Evaluate the quality of your files with FastQC
--------------------------------------------------------

If you installed Dropbox, we can use FastQC to look at the quality of your sequences::

   mkdir /home/ubuntu/Dropbox/fastqc
   /usr/local/share/FastQC/fastqc <.fastq.gz file> --outdir=/home/ubuntu/Dropbox/fastqc

The output will be placed under the 'fastqc' directory in your Dropbox
on your local computer; look for the fastqc_report.html files, and
double click on them to load them into your browser.

Find the right Illumina adapters
--------------------------------

You'll need to know which Illumina sequencing adapters were used for
your library in order to trim them off; do ::

   ls /usr/local/share/adapters/

to see which ones are available.  Below, we will use the TruSeq3-PE.fa
adapters.

.. note::

   You'll need to make sure these are the right adapters for your
   data.  If they are the right adapters, you should see that some of
   the reads are trimmed; if they're not, you won't see anything
   get trimmed.

Adapter trim each pair of files
-------------------------------

(From this point on, you may want to be running things inside of
screen, so that you detach and log out while it's running; see
:doc:`../amazon/using-screen` for more information.)

The files containing paired-end reads are labled as <prefix>_1.fastq.gz and <prefix>_2.fastq.gz. The <prefix> should briefly describe the file and be exactly same for the paired read files.

For *each* of these pairs, run the following::

   # make a temp directory
   mkdir trim
   cd trim

   # run trimmomatic
   java -jar /usr/local/bin/trimmomatic-0.30.jar PE <'_1.fastq.gz' FILE> <'_2.fastq.gz' FILE> s1_pe s1_se s2_pe s2_se ILLUMINACLIP:/usr/local/share/adapters/TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:20:30 AVGQUAL:28

   # compress the files and save it in the working directory
   gzip -9c s1_pe > ../<prefix>_1.pe.fq.gz
   gzip -9c s1_se > ../<prefix>_1.se.fq.gz
   gzip -9c s2_pe > ../<prefix>_2.pe.fq.gz
   gzip -9c s2_se > ../<prefix>_2.se.fq.gz

   # go back up to the working directory and remove the temp directory
   cd ..
   rm -r trim

   # make it hard to delete the files you just created
   chmod u-w *.pe.fq.gz *.se.fq.gz

To get a basic idea of what's going on, please read the '#' comments
above, but, briefly, this set of commands:

* creates a temporary directory, 'trim/'

* runs 'Trimmomatic' in that directory to trim off the adapters, and then
  puts remaining pairs (most of them!) in s1_pe and s2_pe, and any orphaned
  singletons in s1_se and s2_se.

* 'Trimmomatic' also does a 'sliding window trimming approach' (optional): if the quality in window of 20 drops below average score of 30, then the read is trimmed. AVGQUAL is the average quality score below which the read is dropped. LEADING and TRAILING are the number of bases to be trimmed from beginning and end of reads respectively, if the quality score drops below threshold (here, 30). Using 'Trimmomatic' to do quality control ensures that the number of paired reads in s1_pe and s2_pe are same: if any one read in a pair is dropped due to poor quality, its pair is considered as an orphan. This is important becuase several downstream tools (such as mappers) require that the number of reads in paired-end files be exactly the same. 

* Puts the trimmed reads back in the working directory

At the end of this you will have new files ending in '.pe.fq.gz' and
'.se.fq.gz', representing the paired and orphaned quality trimmed
reads, respectively.

Evaluate the quality of your files with FastQC
----------------------------------------------

Use FastQC to look at the quality of your newly-trimmed sequences::

   mkdir /home/ubuntu/Dropbox/fastqc
   /usr/local/share/FastQC/fastqc <'.fq.gz file> --outdir=/home/ubuntu/Dropbox/fastqc

Again, the output will be placed under the 'fastqc' directory in your
Dropbox on your local computer; look for the fastqc_report.html files,
and double click on them to load them into your browser. FastQC also outputs additional files in *_fastqc.zip, where * is the input file ('.fq.gz') name.

You may notice that the reads have low quality-scores in the 'Per base sequence quality' in the '.fq.gz_fastqc.html', especially in the second pair of the paired-end reads. It is a good idea to trim the reads to remove poor-quality ends. 

* Add snapshots of fastqc screens, before and after trimming, using the snapshots from this very example.

Automating this step 
~~~~~~~~~~~~~~~~~~~~

If you have several files to run FastQC on, you can unzip the '_fastqc.zip' files, and look for 'summary.txt' file in the unzipped folders. If you see 'FAIL' or 'WARN' next to 'Per base sequence quality' in this 'summary.txt', it is a good idea to look at the '_fastqc.html' files individually and trim the ends, or decide if the data quality isn't good enough for downstream analyses, and if not, you may not want to use that file. 

A simple script can be written to identify the .fq.gz files that FAIL the 'Per base sequence quality' test, and will narrow down the number of FastQC html reports to look at.

Quality trim each pair of files
-------------------------------

If you are following this example, you should have a bunch of '.pe.fq.gz' files and
a bunch of '.se.fq.gz' files, and html FastQC reports assessing the quality of data in these files. If your fastq files need trimming, do the following ::

	gunzip -c <'.fq.gz' file> | fastx_trimmer -l <length to keep> -z -o <'.qc.fq.gz' outfile>

This first uncompresses the .fq.gz files, trims the reads to specified length, and -z compresses output with gzip.

Automating this step
~~~~~~~~~~~~~~~~~~~~

If all .fq.gz files need trimming, do the following: 

.. ::

   echo 1-quality FILTER `date` >> /root/times.out

This step can be automated with a 'for' loop at the shell prompt.  Try :
::

   for file in *.pe.fq.gz *.se.fq.gz
   do
        echo working with $file
        newfile="$(basename $file .fq.gz)"
        gunzip -c $file | fastx_trimmer -l <length to keep> | gzip -9c \
            > "${newfile}.qc.fq.gz"
   done

What this loop does is:

* for every file ending in pe.fq.gz and se.fq.gz,

* print out a message with the filename,

* uncompresses the original file, passes it through fastx_trimmer, recompresses it,
  and saves it as 'newfile'.qc.fq.gz


Finishing up
------------

You should now have a bunch of files:

   *_1.fastq.gz 	      	 		     - the original data
   *_2.fastq.gz
   *_1.pe.fq.gz, *_2.pe.fq.gz		     - adapter trimmed and filtered pe
   *_1.se.fq.gz, *_2.se.fq.gz		     - adapter trimmed and filtered se
   *.qc.fq.gz							 - FASTX trimmed files

Yikes!  What to do?

Well, first, you can get rid of the original data.  You already have it on a
disk somewhere, right? :
::

   rm *.fastq.gz

Next, you can get rid of the 'pe.fq.gz' and 'se.fq.gz' files, since you
only want the QC files.  So :
::

   rm *.pe.fq.gz *.se.fq.gz

Things to think about
~~~~~~~~~~~~~~~~~~~~~

Note that the filenames, while ugly, are conveniently structured with the
history of what you've done.  This is a good idea.

Also note that we've conveniently named the files so that we can remove
the unwanted ones en masse.  This is a good idea, too.

And finally, make the end product files read-only :
::

   chmod u-w *.qc.fq.gz

to make sure you don't accidentally delete something.

OPTIONAL: Evaluate the quality of your files with FastQC again
--------------------------------------------------------------

We can once again use FastQC to look at the quality of your newly-trimmed sequences::

   mkdir /home/ubuntu/Dropbox/fastqc
   /usr/local/share/FastQC/fastqc *.qc.fq.gz --outdir=/home/ubuntu/Dropbox/fastqc

Again, the output will be placed under the 'fastqc' directory in your
Dropbox on your local computer; look for the fastqc_report.html files,
and double click on them to load them into your browser.

Saving the files
----------------

At this point, you should save these files::

   mkdir save
   mv *.qc.fq.gz save
   du -sk save

If you are running with a data subset for a workshop, do
::

   cp /mnt/work/*.qc.fq.gz /data

to save the QC files for later use.

.. shell stop

This puts the data you want to save into a subdirectory named 'save', and
calculates the size.

Now, create a volume of the given size -- divide by a thousand to get
gigabytes, multiply by 1.1 to make sure you have enough room, and then
follow the instructions in :doc:`../amazon/index`.  Once
you've mounted it properly (I would suggest mounting it on /save
instead of /data!), then do ::

   rsync -av save /save

which will copy all of the files over from the ./save directory onto the
'/save' disk.  Then 'umount /save' and voila, you've got a copy of the files!

Next stop: :doc:`2-mapping`.

